# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01a_data.ipynb (unless otherwise specified).

__all__ = ['get_zappos_db', 'DB_PATH', 'read_zappos_meta', 'simplify_zappos_db', 'skl_tt_split', 'DB_PATH',
           'IMG_SIZE_MD', 'IMG_SIZE', 'ZAPPOS_DF_SIMPLIFIED', 'ZAPPOS_FEATS_ALL', 'ZAPPOS_FEATS_ALL_SORT',
           'ZAPPOS_FEATS_MD', 'creat_full_local_categorydirs', 'create_test_train_directories']

# Cell
from .imports import *
from .core import *
import scipy.io as sio

# Cell

DB_PATH = "../../Projects/DATABASE"

def get_zappos_db():

    # don't use the "square" versions because they are excessively padded.  we'll simply pad with "white"
    #url_images = "http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images-square.zip"
    url_images = "http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images.zip"
    # the images are wider than tall with the product already taking up aproximately the whole vertical dimension
    url_meta = "http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-data.zip"

    DATA_path = Path.home()/'Projects/DATABASE'
    path_meta = untar_data(url_meta, dest=DATA_path)
    path_images = untar_data(url_images,dest=DATA_path)

# Cell

def read_zappos_meta():
    def _path_from_mat(fname):
        """ reads zappos imagepath from matlab file"""
        data = sio.loadmat(fname)['imagepath']
        return [i[0][0] for i in data]

    image_path = _path_from_mat(path_meta/'image-path.mat')
    df = pd.read_csv(path_meta/'meta-data.csv')

    df["path"]=image_path

    # ad sub-categories (one-hot)
    categories=pd.read_csv(path_meta/'meta-data-bin.csv')
    df = pd.merge(df, categories,  how='left', on='CID')# left_on=['CID'], right_on = ['CID'])


    # fix the path by remove trailing periods in folder names
    df.loc[df.path.str.contains("./",regex=False),"path"] = [i.replace("./","/") for i in df.loc[df.path.str.contains("./",regex=False),"path"]]
    df.loc[df.path.str.contains("Levi\'s ",regex=False),"path"] = [i.replace("Levi\'s ","Levis ") for i in df.loc[df.path.str.contains("Levi\'s ",regex=False),"path"]]
    # create brands and category stubs...
    df['path_and_file'] = df.path.apply(lambda path: (os.path.normpath(path)).split(os.sep) )
    df_to_add = pd.DataFrame(df['path_and_file'].tolist(), columns=['Category1','Category2','Brand','Filename'])

    df = df.merge(df_to_add, left_index=True, right_index=True)
    #df = pd.merge(df, df_to_add, left_index=True, right_index=True)
    return df


# Cell

def simplify_zappos_db(df):
    " simplifies the db (df)"
    # add our "sneaker category"
    df.loc[:,'Sneakers'] = (df['Category2'] == 'Sneakers and Athletic Shoes')

    # refine boot
    df.loc[:,'Boots'] = (  (df.Category1 == 'Boots')
                         & (df.Category2 != 'Knee High')
                         & (df.Category2 != 'Over the Knee')
                         & (df.Category2 != 'Prewalker Boots') )

    # refine shoes
    df.loc[:,'Shoes'] = (  (df.Category1 == 'Shoes')
                         & (df.Category2 != 'Sneakers and Athletic Shoes')
                         & (df.Category2 != 'Crib Shoes')
                         & (df.Category2 != 'Firstwalker')
                         & (df.Category2 != 'Prewalker') )

    # refine shoes
    df.loc[:,'Slippers'] = (  (df.Category1 == 'Shoes')
                         & (df.Category2 != 'Sneakers and Athletic Shoes')
                         & (df.Category2 != 'Crib Shoes')
                         & (df.Category2 != 'Firstwalker')
                         & (df.Category2 != 'Prewalker') )

    # define Slippers
    df.loc[:,'Slippers'] = (df.Category1 == 'Slippers')
    ############
    #remove ([ 'Boys',  'Boys;Girls', 'Girls','Women;Girls', nan

    mens =  df['Gender'] == 'Men'
    womens =  df['Gender'] == 'Women'
    etc =  df['Gender'].str.contains('Men;', na=False)

    df.loc[:,'Adult'] = mens | womens | etc

    df.loc[:,'Mens'] = mens
    df.loc[:,'Womens'] = womens

    df.loc[:,'OGcategory'] = df.Category
    df.loc[:,'Category'] = pd.NA

    df.loc[(df.Shoes==1),'Category'] = 'Shoes'
    df.loc[(df.Boots==1),'Category'] = 'Boots'
    df.loc[(df.Sneakers==1),'Category'] = 'Sneakers'
    df.loc[(df.Slippers==1),'Category'] = 'Slippers'


    # make some expository columns
    keep_columns = ['CID','Category',
                     'path','path_and_file',
                     'Category1', 'Category2','OGcategory'
                     'Brand','Filename',
                     'Sneakers','Boots',
                     'Shoes', 'Slippers','Adult',
                     'Gender']

    df = df.filter(items=keep_columns)
    #keep Adult, Sneakers, Boots, Shoes, Slippers
    keep_rows = (df.Sneakers | df.Boots | df.Shoes| df.Slippers) & (df.Adult)
    #Only keep Adult (men+women) and Sneakers, Boots, Shoes
    df = df[keep_rows.values]
    return df

# Cell

def skl_tt_split(df):
    "adds stratified train-validate-test via sklearn"


    X = df.index
    y = df.Category

    train_ratio = 0.70
    validation_ratio = 0.15

    # keep
    test_ratio = 0.15

    # train is now 75% of the entire data set
    # the _junk suffix means that we drop that variable completely
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio,stratify=y, random_state=666)

    # test is now 10% of the initial data set
    # validation is now 15% of the initial data set
    x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio),stratify=y_test, random_state=666)
    # pack into the dataframe
    df.loc[:,'train'] = False
    df.loc[:,'test'] = False
    df.loc[:,'validate'] = False
    df.loc[:,'t_t_v'] = 'train'
    df.loc[x_train,'train'] = True
    df.loc[x_test,'test'] = True
    df.loc[x_val,'validate'] = True
    df.loc[x_test,'t_t_v'] = 'test'
    df.loc[x_val,'t_t_v'] = 'valid'



# Cell
from .imports import *
from .core import *

### might be fastai wrappers to do this elegantly... (untar_data?)
import os
from glob import iglob
from os.path import join,basename
import shutil
import random



# Cell

# this should go into a utils or cfg module
#DATA_path = Path.home()/'Projects/DATABASE'
#DB_path = Path.home()/'Projects/DATABASE'
DB_PATH = "../../Projects/DATABASE"


IMG_SIZE_MD = 160
IMG_SIZE = IMG_SIZE_MD

ZAPPOS_DF_SIMPLIFIED = "zappos-50k-simplified_sort"

ZAPPOS_FEATS_ALL = "zappos-50k-mobilenetv2-features_"
ZAPPOS_FEATS_ALL_SORT = "zappos-50k-mobilenetv2-features_sort_3"

ZAPPOS_FEATS_MD = f"mobilenetv2-features_medium"


# Cell

def creat_full_local_categorydirs(df):


    # create full set
    print('_'*30)
    print('Creating full local category set....')
    print('_'*30)


    for idx in df.index:
        save_path = join(ldata_path,df.loc[idx,'CategoryDir'])

        #print(save_path)
        if not os.path.exists(save_path):
            os.makedirs(save_path)
        img =  join(data_path,df.loc[idx,'path'])
        #print(img)
        shutil.copy2(img,save_path)


# Cell

def create_test_train_directories(df):

    # create test set
    print('_'*30)
    print('Creating full train set....')
    print('_'*30)

    for idx in df.index:
        save_path = join(train_path,df.loc[idx,'CategoryDir'])
        #print(save_path)
        if not os.path.exists(save_path):
            os.makedirs(save_path)
        img =  join(data_path,df.loc[idx,'path'])
        #print(img)
        shutil.copy2(img,save_path)
    # create test set
    print('_'*30)
    print('Creating test set....')
    print('_'*30)

    #instead of looking at the files, lets just use the database

    for file in iglob(join(train_path,'*')):
    #for file in df.path:
        save_path = join(test_path, basename(file))

        if not os.path.exists(save_path):
            os.makedirs(save_path)

        total_imgs = [x for x in iglob(join(file,'*'))]

        rand_amt = 2* 0.12 * len(total_imgs)  # select 24% of data from each category as testing + validation set
        print(rand_amt)
        test_imgs= []
        for i in range(int(rand_amt)):
            img = random.choice(total_imgs)
            if img not in test_imgs:
                #print(img)
                df.loc[df.Filename == basename(img),'train'] = 0
                df.loc[df.Filename == basename(img),'test'] = 1
                shutil.move(img,save_path)
                test_imgs.append(img)


                # create validation set
    print('_'*30)
    print('Creating validation set....')
    print('_'*30)

    #instead of looking at the files, lets just use the database
    for file in iglob(join(test_path,'*')):
    #for file in df.path:
        save_path = join(val_path, basename(file))

        if not os.path.exists(save_path):
            os.makedirs(save_path)

        total_imgs = [x for x in iglob(join(file,'*'))]

        rand_amt = 0.5 * len(total_imgs)  # select 50% of data from each category to split evenly between test and validation
        print(rand_amt)
        test_imgs= []
        for i in range(int(rand_amt)):
            img = random.choice(total_imgs)
            if img not in test_imgs:
                #print(img)
                df.loc[df.Filename == basename(img),'test'] = 0
                df.loc[df.Filename == basename(img),'validation'] = 1
                shutil.move(img,save_path)
                test_imgs.append(img)


