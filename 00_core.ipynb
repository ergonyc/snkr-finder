{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# snkrfinder\n",
    "\n",
    "> API details:\n",
    "    - sets up the data strucures and tools for Snkr Finder\n",
    "    \n",
    "    \n",
    "\n",
    "### version 0.2 Jan 2021 (0.1 Insight tf/keras)\n",
    "\n",
    "# OVERVIEW\n",
    "\n",
    "This is a project initiated while an Insight Data Science fellow.  It grew out of my interest in making data driven tools in the fashion/retail space I had most recently been working.   The original over-scoped idea was to make a shoe desighn tool which could quickly develop some initial sneakers based on choosing some examples, and some text descriptors.  Designs are constrained by the \"latent space\" defined (discovered?) by a database of shoe images.  However, given the 3 week sprint allowed for development, I pared the tool down to a simple \"aesthetic\" recommender for sneakers, using the same idea of utilizing an embedding space defined by the database fo shoe images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we need in this ?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- pretrained architectures\n",
    "    - mobilenet v2 (from torchvision)\n",
    "    - resnet (xresnet, from fastai)\n",
    "\n",
    "\n",
    "- feature extractor\n",
    "    - headless model with \"Identity\" output\n",
    "    \n",
    "    \n",
    "- data handling\n",
    "    - pack into dataframe\n",
    "    \n",
    "    - sort files into:\n",
    "        - train / validate / test?\n",
    "        - category\n",
    "\n",
    "    - munging and cleaning and merging\n",
    "        - zappos 50 k\n",
    "        - scraped data\n",
    "            - goat\n",
    "            - sns\n",
    "    - datacleaner GUI\n",
    "\n",
    "- visualization\n",
    "    - embeddings\n",
    "        - umap (replace tsne)\n",
    "    - images \n",
    "    \n",
    "\n",
    "- find \"similar\" via knn from scikit learn\n",
    "\n",
    "\n",
    "GUI\n",
    "    - following the fastai wiget model\n",
    "    - make some classes \n",
    "        - da\n",
    "\n",
    "EXTENSION\n",
    "    MODELS\n",
    "        -categorizers\n",
    "    AE\n",
    "    VAE\n",
    "    CVAE\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "def get_mnetV2_feature_net(to_cuda=False):\n",
    "    \"\"\"\n",
    "    get mnetv2 from torchvision and put an Identity \"head\" on it\n",
    "    \"\"\"\n",
    "    ## use an \"identity\" layer to replace 1000 category classifier\n",
    "    class Identity(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Identity, self).__init__()\n",
    "\n",
    "        def forward(self, x):\n",
    "            return x\n",
    "    mnetv2  = torchvision.models.mobilenet_v2(pretrained=True)\n",
    "    mnetv2.classifier = Identity()\n",
    "    if to_cuda:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    mnetv2 = mnetv2.to(device)\n",
    "    mnetv2.eval()\n",
    "\n",
    "    # just incase we forget the no_grad()\n",
    "    for param in mnetv2.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    return mnetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "def munnymunnymunny(makesmoney):\n",
    "    print(\"munnnnnnny!\")\n",
    "    profit = f\"billz{1000000000}\"\n",
    "    return profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "DBS = {\"zappos\": \"/ut-zap50k-images\",\n",
    "      \"sns\": \"scraped/sns/im\",\n",
    "      \"goat\": \"scraped/goat/im\"}\n",
    "\n",
    "LATENT_SIZE_SM = 64\n",
    "LATENT_SIZE_MD = 128\n",
    "IMG_SIZE_SM = 128\n",
    "IMG_SIZE_MD = 160\n",
    "IMG_SIZE = IMG_SIZE_MD\n",
    "LATENT_SIZE = LATENT_SIZE_MD\n",
    "\n",
    "ZAPPOS_DF_SIMPLIFIED = \"zappos-50k-simplified_sort\"\n",
    "\n",
    "ZAPPOS_FEATS_ALL = \"zappos-50k-mobilenetv2-features_\"\n",
    "ZAPPOS_FEATS_ALL_SORT = \"zappos-50k-mobilenetv2-features_sort_3\"\n",
    "\n",
    "ZAPPOS_FEATS_MD = f\"mobilenetv2-features_medium\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
